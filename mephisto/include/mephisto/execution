#ifndef MEPHISTO_EXECUTION_H
#define MEPHISTO_EXECUTION_H


#include <memory>
#include <alpaka/alpaka.hpp>
#include <libdash.h>
#include <dash/Execution.h>
#include <mephisto/buffer>
#include <mephisto/algorithm/copy>
#include <mephisto/algorithm/for_each>

namespace mephisto {
namespace execution {

  template<typename F>
  class Kernel
{
public:
    //-----------------------------------------------------------------------------
    //! The kernel entry point.
    //!
    //! \tparam TAcc The accelerator environment to be executed on.
    //! \tparam TElem The matrix element type.
    //! \param acc The accelerator to be executed on.
    //! \param A The first source vector.
    //! \param B The second source vector.
    //! \param C The destination vector.
    //! \param numElements The number of elements.
    ALPAKA_NO_HOST_ACC_WARNING
    template <typename TAcc, typename TElem, typename TIdx>
    ALPAKA_FN_ACC auto operator()(
        TAcc const &       acc,
        TElem const *const A,
        TElem const *const B,
        TElem *const       C,
        TIdx const &       numElements) const -> void
    {
    }
};

/**
 * An executor that uses alpaka to do the work.
 */
template<class AlpakaContext>
struct AlpakaExecutor {
    AlpakaContext ctx;

    // Wrapper entity
    using Entity = typename AlpakaContext::entity_t;
    // Alpaka entity/accelerator
    using Acc    = typename Entity::acc_t;

    AlpakaExecutor(AlpakaContext context)
      : ctx(context)
    {
    }

    template <
        class Function,
        class Shape,
        class ResultFactory,
        class SharedFactory>
    void bulk_twoway_execute(
        Function f, Shape iter, ResultFactory result, SharedFactory sf) const
    {
      auto &pattern = iter.pattern();

      using PatternT   = typename Shape::pattern_type;
      using value_type = typename Shape::value_type;
      using dim        = alpaka::dim::DimInt<PatternT::ndim()>;

      // Assume we have a LocalPattern that lets us iterate over local blocks
      // for each accelerator
      for (auto &entity : ctx.entities()) {
        for (auto block : pattern.blocks_local_for_entity(entity)) {
          using ViewSpec = decltype(block);

          // do work on this block

          // 1. create workdiv from block
          alpaka::vec::Vec<dim, std::size_t> const extents(std::size_t{1},std::size_t{1},std::size_t{1});
          auto                                     offsets = block.offsets();
          alpaka::workdiv::WorkDivMembers<dim, std::size_t> const workDiv{
              alpaka::workdiv::getValidWorkDiv<Acc>(entity, extents, extents)};
          // 2. create host buffer, TODO: simplify
          auto block_begin =
              static_cast<typename Shape::pointer>(iter.globmem().begin()) +
              pattern.global_at(block.offsets());

          auto host_buf =
              mephisto::HostDataBuffer<value_type, Entity, ViewSpec>{
                  block, block_begin.local()};

          // 3. copy the buffer to the entity
          auto device_buf = mephisto::put(ctx.queue(), host_buf, entity);
          // 4. work
          Kernel<Function> kernel;

          auto const taskKernel(alpaka::kernel::createTaskKernel<Acc>(
              workDiv,
              kernel,
              alpaka::mem::view::getPtrNative(device_buf.begin()),
              block.size()));

          alpaka::queue::enqueue(ctx.queue(), kernel);

          // 5. copy data back
          mephisto::get(ctx.queue(), device_buf, host_buf);
        }
      }
    }

    AlpakaContext &context() const
    {
        return ctx;
    }
};

template <class Entity, class Queue>
struct AlpakaExecutionContext {
  using host_t   = alpaka::dev::DevCpu;
  using entity_t = typename std::remove_cv<Entity>::type;
  using acc_t    = typename Entity::acc_t;

  host_t _host_device;
  Queue     _queue;

  AlpakaExecutionContext()
    : _host_device(alpaka::pltf::getDevByIdx<alpaka::pltf::PltfCpu>(0u)), _queue(_host_device)
  {
  }

  auto entities() const {
    return entity_t::all();
  }

  auto queue() const {
    return _queue;
  }
};

// See C++17's std::execution::par
// Additionally we enforce that the policy has an executor
template <class Executor>
struct ParallelPolicy {
  Executor ex;

  ParallelPolicy(Executor ex)
    : ex(ex)
  {
  }

  const Executor &executor() const
  {
    return ex;
  }
};

template <class Executor>
ParallelPolicy<Executor> make_parallel_policy(Executor ex)
{
    return ParallelPolicy<Executor>(ex);
}
}  // namespace execution
}  // namespace mephisto

namespace dash {

template <class Executor>
struct is_execution_policy<mephisto::execution::ParallelPolicy<Executor>>
    : public std::true_type {
};

}  // namespace dash

#endif
